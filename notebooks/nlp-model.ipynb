{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9797304,"sourceType":"datasetVersion","datasetId":5974060}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. BoW","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\ndf = pd.read_csv('/kaggle/input/mda-reports/MDA_dataset_10K.csv', index_col=0)\ndf.dropna(inplace=True)\n\nlr = LogisticRegression(max_iter=1000, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T18:15:44.793963Z","iopub.execute_input":"2024-11-25T18:15:44.794617Z","iopub.status.idle":"2024-11-25T18:15:46.042454Z","shell.execute_reply.started":"2024-11-25T18:15:44.794581Z","shell.execute_reply":"2024-11-25T18:15:46.041558Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### 1.1. Unigrams","metadata":{}},{"cell_type":"code","source":"cv = CountVectorizer(stop_words='english', min_df=5)\n\nX = df['MDA'].str[22500:24500]\ny = df['target_3']\nmask = X.str.len() > 0\nX = X[mask]\ny = y[mask]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\nX_train_counts = cv.fit_transform(X_train)\nX_test_counts = cv.transform(X_test)\n\nlr.fit(X_train_counts, y_train)\n\ny_train_pred = lr.predict(X_train_counts)\ny_test_pred = lr.predict(X_test_counts)\n\nprint(\"Accuracy (train):\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Accuracy (test):\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2024-11-25T18:15:46.044274Z","iopub.execute_input":"2024-11-25T18:15:46.044987Z","iopub.status.idle":"2024-11-25T18:15:46.753045Z","shell.execute_reply.started":"2024-11-25T18:15:46.044941Z","shell.execute_reply":"2024-11-25T18:15:46.752150Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy (train):\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00       354\n         1.0       1.00      1.00      1.00       359\n\n    accuracy                           1.00       713\n   macro avg       1.00      1.00      1.00       713\nweighted avg       1.00      1.00      1.00       713\n\nAccuracy (test):\n              precision    recall  f1-score   support\n\n         0.0       0.57      0.57      0.57       114\n         1.0       0.60      0.60      0.60       124\n\n    accuracy                           0.59       238\n   macro avg       0.59      0.59      0.59       238\nweighted avg       0.59      0.59      0.59       238\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### 1.2. Bigrams","metadata":{}},{"cell_type":"code","source":"cv = CountVectorizer(stop_words='english', min_df=5, ngram_range=(2, 2))\n\nX = df['MDA'].str[45500:48500]\ny = df['target_3']\nmask = X.str.len() > 0\nX = X[mask]\ny = y[mask]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\nX_train_counts = cv.fit_transform(X_train)\nX_test_counts = cv.transform(X_test)\n\nlr.fit(X_train_counts, y_train)\n\ny_train_pred = lr.predict(X_train_counts)\ny_test_pred = lr.predict(X_test_counts)\n\nprint(\"Accuracy (train):\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Accuracy (test):\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2024-11-25T18:15:46.754729Z","iopub.execute_input":"2024-11-25T18:15:46.755390Z","iopub.status.idle":"2024-11-25T18:15:47.243428Z","shell.execute_reply.started":"2024-11-25T18:15:46.755348Z","shell.execute_reply":"2024-11-25T18:15:47.242598Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy (train):\n              precision    recall  f1-score   support\n\n         0.0       0.99      1.00      1.00       337\n         1.0       1.00      0.99      1.00       351\n\n    accuracy                           1.00       688\n   macro avg       1.00      1.00      1.00       688\nweighted avg       1.00      1.00      1.00       688\n\nAccuracy (test):\n              precision    recall  f1-score   support\n\n         0.0       0.61      0.59      0.60       121\n         1.0       0.56      0.59      0.57       109\n\n    accuracy                           0.59       230\n   macro avg       0.59      0.59      0.59       230\nweighted avg       0.59      0.59      0.59       230\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### 1.3. Trigrams","metadata":{}},{"cell_type":"code","source":"cv = CountVectorizer(stop_words='english', min_df=5, ngram_range=(3, 3))\n\nX = df['MDA'].str[56500:59500]\ny = df['target_3']\nmask = X.str.len() > 0\nX = X[mask]\ny = y[mask]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\nX_train_counts = cv.fit_transform(X_train)\nX_test_counts = cv.transform(X_test)\n\nlr.fit(X_train_counts, y_train)\n\ny_train_pred = lr.predict(X_train_counts)\ny_test_pred = lr.predict(X_test_counts)\n\nprint(\"Accuracy (train):\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Accuracy (test):\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2024-11-25T18:15:47.409895Z","iopub.execute_input":"2024-11-25T18:15:47.410595Z","iopub.status.idle":"2024-11-25T18:15:47.854289Z","shell.execute_reply.started":"2024-11-25T18:15:47.410565Z","shell.execute_reply":"2024-11-25T18:15:47.853350Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy (train):\n              precision    recall  f1-score   support\n\n         0.0       0.84      0.93      0.88       322\n         1.0       0.92      0.84      0.88       345\n\n    accuracy                           0.88       667\n   macro avg       0.88      0.88      0.88       667\nweighted avg       0.89      0.88      0.88       667\n\nAccuracy (test):\n              precision    recall  f1-score   support\n\n         0.0       0.62      0.66      0.64       122\n         1.0       0.55      0.51      0.53       101\n\n    accuracy                           0.59       223\n   macro avg       0.59      0.59      0.59       223\nweighted avg       0.59      0.59      0.59       223\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# 2. TD-IDF","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\ndf = pd.read_csv('/kaggle/input/mda-reports/MDA_dataset_10K.csv', index_col=0)\ndf.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T18:15:49.627192Z","iopub.execute_input":"2024-11-25T18:15:49.627975Z","iopub.status.idle":"2024-11-25T18:15:50.853410Z","shell.execute_reply.started":"2024-11-25T18:15:49.627941Z","shell.execute_reply":"2024-11-25T18:15:50.852565Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"### 2.1. Unigrams","metadata":{}},{"cell_type":"code","source":"X = df['MDA'].str[500:3500]\ny = df['target_3']\nmask = X.str.len() > 0\nX = X[mask]\ny = y[mask]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\ntfidf = TfidfVectorizer(stop_words='english', min_df=5, max_df=1.0, ngram_range=(1, 1))\ntfidf.fit(X_train)\nX_train = tfidf.transform(X_train)\nX_test = tfidf.transform(X_test)\n\nlr = LogisticRegression(max_iter=1000, penalty='l2')\nlr.fit(X_train, y_train)\n\ny_train_pred = lr.predict(X_train)\ny_test_pred = lr.predict(X_test)\n\nprint(\"Accuracy (train):\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Accuracy (test):\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2024-11-25T18:15:52.278226Z","iopub.execute_input":"2024-11-25T18:15:52.278577Z","iopub.status.idle":"2024-11-25T18:15:52.771420Z","shell.execute_reply.started":"2024-11-25T18:15:52.278547Z","shell.execute_reply":"2024-11-25T18:15:52.770567Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy (train):\n              precision    recall  f1-score   support\n\n         0.0       0.80      0.79      0.79       368\n         1.0       0.79      0.80      0.80       368\n\n    accuracy                           0.79       736\n   macro avg       0.79      0.79      0.79       736\nweighted avg       0.79      0.79      0.79       736\n\nAccuracy (test):\n              precision    recall  f1-score   support\n\n         0.0       0.57      0.58      0.58       118\n         1.0       0.61      0.59      0.60       128\n\n    accuracy                           0.59       246\n   macro avg       0.59      0.59      0.59       246\nweighted avg       0.59      0.59      0.59       246\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"### 2.1. Bigramms","metadata":{}},{"cell_type":"code","source":"X = df['MDA'].str[60500:66500]\ny = df['target_3']\nmask = X.str.len() > 0\nX = X[mask]\ny = y[mask]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\ntfidf = TfidfVectorizer(stop_words='english', min_df=5, max_df=1.0, ngram_range=(1, 2))\ntfidf.fit(X_train)\nX_train = tfidf.transform(X_train)\nX_test = tfidf.transform(X_test)\n\nlr = LogisticRegression(max_iter=1000)\nlr.fit(X_train, y_train)\n\ny_train_pred = lr.predict(X_train)\ny_test_pred = lr.predict(X_test)\n\nprint(\"Accuracy (train):\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Accuracy (test):\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2024-11-25T17:52:00.712729Z","iopub.execute_input":"2024-11-25T17:52:00.713115Z","iopub.status.idle":"2024-11-25T17:52:02.567556Z","shell.execute_reply.started":"2024-11-25T17:52:00.713082Z","shell.execute_reply":"2024-11-25T17:52:02.566470Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy (train):\n              precision    recall  f1-score   support\n\n         0.0       0.88      0.87      0.87       324\n         1.0       0.87      0.88      0.88       329\n\n    accuracy                           0.87       653\n   macro avg       0.87      0.87      0.87       653\nweighted avg       0.87      0.87      0.87       653\n\nAccuracy (test):\n              precision    recall  f1-score   support\n\n         0.0       0.59      0.54      0.57       114\n         1.0       0.54      0.59      0.56       104\n\n    accuracy                           0.56       218\n   macro avg       0.57      0.57      0.56       218\nweighted avg       0.57      0.56      0.56       218\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### 2.3. Trigrams","metadata":{}},{"cell_type":"code","source":"X = df['MDA'].str[500:4500]\ny = df['target_3']\nmask = X.str.len() > 0\nX = X[mask]\ny = y[mask]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\ntfidf = TfidfVectorizer(stop_words='english', min_df=5, max_df=1.0, ngram_range=(1, 3))\ntfidf.fit(X_train)\nX_train = tfidf.transform(X_train)\nX_test = tfidf.transform(X_test)\n\nlr = LogisticRegression(max_iter=1000, penalty='l2', n_jobs=-1)\nlr.fit(X_train, y_train)\n\ny_train_pred = lr.predict(X_train)\ny_test_pred = lr.predict(X_test)\n\nprint(\"Accuracy (train):\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Accuracy (test):\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2024-11-25T17:52:05.772958Z","iopub.execute_input":"2024-11-25T17:52:05.773582Z","iopub.status.idle":"2024-11-25T17:52:07.546376Z","shell.execute_reply.started":"2024-11-25T17:52:05.773552Z","shell.execute_reply":"2024-11-25T17:52:07.543074Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy (train):\n              precision    recall  f1-score   support\n\n         0.0       0.79      0.81      0.80       368\n         1.0       0.80      0.79      0.80       368\n\n    accuracy                           0.80       736\n   macro avg       0.80      0.80      0.80       736\nweighted avg       0.80      0.80      0.80       736\n\nAccuracy (test):\n              precision    recall  f1-score   support\n\n         0.0       0.57      0.63      0.60       118\n         1.0       0.62      0.56      0.59       128\n\n    accuracy                           0.59       246\n   macro avg       0.59      0.59      0.59       246\nweighted avg       0.60      0.59      0.59       246\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# 3. DistilBERT","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import DistilBertTokenizer, DistilBertModel\nimport os\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom tqdm.notebook import tqdm\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndf10q = pd.read_csv('/kaggle/input/mda-reports/MDA_dataset_10K.csv', index_col=0)\ndf10q.dropna(inplace=True)\n\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertModel.from_pretrained('distilbert-base-uncased')\nmodel = torch.nn.DataParallel(model).to(device)\n\ntexts = df10q['MDA'].tolist()\ntexts = [text[42080:47080] for text in texts]\n\nlabels = df10q['target_10_index'].tolist()\n\nbatch_size = 80\nembeddings = []\nall_labels = []\n\nfor i in tqdm(range(0, len(texts), batch_size), desc=\"Processing batches\"):\n    batch_texts = texts[i:i + batch_size]\n    batch_labels = labels[i:i + batch_size]\n\n    tokens = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n\n    with torch.no_grad():\n        outputs = model(**tokens)\n\n    batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n\n    embeddings.extend(batch_embeddings)\n    all_labels.extend(batch_labels)\n\n    del tokens, outputs\n    torch.cuda.empty_cache()\n\nX = np.array(embeddings)\ny = np.array(all_labels)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\nlr_clf = LogisticRegression(max_iter=1000)\nlr_clf.fit(X_train, y_train)\n\npred_labels = lr_clf.predict(X_test)\ny_train_pred = lr_clf.predict(X_train)\n\nprint(\"Accuracy (train):\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Accuracy (test):\")\nprint(classification_report(y_test, pred_labels))","metadata":{"execution":{"iopub.status.busy":"2024-12-06T18:02:02.542169Z","iopub.execute_input":"2024-12-06T18:02:02.542983Z","iopub.status.idle":"2024-12-06T18:02:28.450935Z","shell.execute_reply.started":"2024-12-06T18:02:02.542946Z","shell.execute_reply":"2024-12-06T18:02:28.448992Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing batches:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14e75ebe6774348bb85af9adc179579"}},"metadata":{}},{"name":"stdout","text":"Accuracy (train):\n              precision    recall  f1-score   support\n\n         0.0       0.76      0.54      0.63       402\n         1.0       0.67      0.85      0.75       448\n\n    accuracy                           0.70       850\n   macro avg       0.71      0.69      0.69       850\nweighted avg       0.71      0.70      0.69       850\n\nAccuracy (test):\n              precision    recall  f1-score   support\n\n         0.0       0.61      0.46      0.52       136\n         1.0       0.59      0.73      0.65       148\n\n    accuracy                           0.60       284\n   macro avg       0.60      0.59      0.59       284\nweighted avg       0.60      0.60      0.59       284\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# 4. GPT-2","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import GPT2Tokenizer, GPT2Model\nimport torch\nfrom tqdm.notebook import tqdm \nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndf10q = pd.read_csv('/kaggle/input/mda-reports/MDA_dataset_10K.csv', index_col=0)\ndf10q.dropna(inplace=True)  \n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2', clean_up_tokenization_spaces=True)\nmodel = GPT2Model.from_pretrained('gpt2')\nmodel = torch.nn.DataParallel(model, device_ids=[0, 1]).to(device)\n\ntokenizer.pad_token = tokenizer.eos_token\n\ntexts = df10q['MDA'].tolist()\ntexts = [text[7500:10500] for text in texts] \nlabels = df10q['target_1_index'].tolist()\n\n\nembeddings = []\nall_labels = []\n\nbatch_size = 80\nfor i in tqdm(range(0, len(texts), batch_size), desc=\"Processing batches\"):\n    batch_texts = texts[i:i + batch_size]\n    batch_labels = labels[i:i + batch_size]\n\n    tokens = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n\n    with torch.no_grad():\n        outputs = model(**tokens)\n\n    batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n\n    embeddings.extend(batch_embeddings)\n    all_labels.extend(batch_labels)\n\n    del tokens, outputs\n    torch.cuda.empty_cache()\n\nX = np.array(embeddings)\ny = np.array(all_labels)\n\nX_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\nlogistic_model = LogisticRegression(max_iter=3000, penalty='l1', solver='liblinear', C=3.0)  \nlogistic_model.fit(X_train, y_train)\n\ny_test_pred = logistic_model.predict(X_test)\ny_train_pred = logistic_model.predict(X_train)\n\nprint(\"Accuracy (train):\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Accuracy (test):\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2024-11-28T15:45:45.418217Z","iopub.execute_input":"2024-11-28T15:45:45.418758Z","iopub.status.idle":"2024-11-28T15:47:15.624774Z","shell.execute_reply.started":"2024-11-28T15:45:45.418709Z","shell.execute_reply":"2024-11-28T15:47:15.622930Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d19b77c2c941446a93189a6a1cdc8b96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfaa996c5ed744a09ae2999e4b07078a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"712e9ecc0b444313a1ebacb7ebd4c3ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc062dbcc42740e597af6073b02673f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0537f57812eb4ccd9648efd856e9ea9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a09f270bc824148a21b8078a63d75a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing batches:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a58e8e1c77fd4cde92d6d806ebba9c62"}},"metadata":{}},{"name":"stdout","text":"Accuracy (train):\n              precision    recall  f1-score   support\n\n         0.0       0.76      0.73      0.74       439\n         1.0       0.72      0.75      0.74       411\n\n    accuracy                           0.74       850\n   macro avg       0.74      0.74      0.74       850\nweighted avg       0.74      0.74      0.74       850\n\nAccuracy (test):\n              precision    recall  f1-score   support\n\n         0.0       0.58      0.57      0.57       139\n         1.0       0.59      0.61      0.60       145\n\n    accuracy                           0.59       284\n   macro avg       0.59      0.59      0.59       284\nweighted avg       0.59      0.59      0.59       284\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 4. Finbert","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import BertTokenizer, BertModel\nimport os\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom tqdm.notebook import tqdm\nfrom sklearn.svm import SVC\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndf = pd.read_csv('/kaggle/input/mda-reports/MDA_dataset_10K.csv', index_col=0)\ndf.dropna(inplace=True)\n\ntokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\nmodel = BertModel.from_pretrained('ProsusAI/finbert')\nmodel = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n\ntexts = df['MDA'].tolist()\ntexts = [text[46000:51000] for text in texts]\n\nlabels = df['target_10_index'].tolist()\n\nbatch_size = 80\nembeddings = []\nall_labels = []\n\nfor i in tqdm(range(0, len(texts), batch_size), desc=\"Processing batches\"):\n    batch_texts = texts[i:i + batch_size]\n    batch_labels = labels[i:i + batch_size]\n\n    tokens = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n\n    with torch.no_grad():\n        outputs = model(**tokens)\n\n    batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n\n    embeddings.extend(batch_embeddings)\n    all_labels.extend(batch_labels)\n\n    del tokens, outputs\n    torch.cuda.empty_cache()\n\nX = np.array(embeddings)\ny = np.array(all_labels)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\nlr = LogisticRegression(max_iter=3000, penalty='l2')  \nlr.fit(X_train, y_train)\n\ny_test_pred=lr.predict(X_test)\ny_train_pred=lr.predict(X_train)\n\nprint(\"Accuracy (train):\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Accuracy (test):\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2024-12-06T06:49:19.354724Z","iopub.execute_input":"2024-12-06T06:49:19.355082Z","iopub.status.idle":"2024-12-06T06:50:20.819500Z","shell.execute_reply.started":"2024-12-06T06:49:19.355050Z","shell.execute_reply":"2024-12-06T06:50:20.818122Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfa89afd471e4036a51230cd033ad5dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fb83f542e124800b2b797d5626b5839"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3662b9436d0042f8b6ddb5ce026f89a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f2ce2453c4b4762bdb61c05509d0f32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad5ca0905216451e83efd7f15f54b0f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing batches:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b26aff91cd10460a8e5251c2d2f83dfe"}},"metadata":{}},{"name":"stdout","text":"Accuracy (train):\n              precision    recall  f1-score   support\n\n         0.0       0.80      0.60      0.69       402\n         1.0       0.71      0.86      0.78       448\n\n    accuracy                           0.74       850\n   macro avg       0.75      0.73      0.73       850\nweighted avg       0.75      0.74      0.73       850\n\nAccuracy (test):\n              precision    recall  f1-score   support\n\n         0.0       0.59      0.47      0.52       136\n         1.0       0.59      0.70      0.64       148\n\n    accuracy                           0.59       284\n   macro avg       0.59      0.59      0.58       284\nweighted avg       0.59      0.59      0.59       284\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}